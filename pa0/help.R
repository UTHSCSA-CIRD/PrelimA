helpList<-list(
            rvarHelp="The more equally represented all the other variables are within each group, the better protected your results are from confounding effects. Of course, that is not always possible-- a mouse will not change its sex part-way through and experiment, and even if you can change the treatment it receives that will create more problems than it solves unless you planned the experiment as a cross-over study to begin with. But, the variables that DO have more than one value within the same group show up here. The app then tries them all individually and in combination until it finds the ones that most need to be corrected for group-to-group variation. This will show up as the random slopes version of the model in your results. You should generally leave all the variables selected (the app will use only the ones that require it), but if you know that two of them are very closely related (for example, body weight and scaled body weight) then you should pick one to leave out, possibly the same one you leave out of the predictor variables below. If you don't know which ones to leave out, that's a question for your statistician, code-words 'variable selection' and 'multi-collinearity'. If there is a variable you expect to see on this menu but do not, either it's already taken by one of the above menu choices (which is fine) or for the grouping you chose there exist groups within which this variable does not change. Depending on how extreme this confounding effect is, it may or may not invalidate the analysis and the only way to make sure is to ask your statistician. Code-word 'confounding variable'.",
            gvarHelp="Are your data grouped in some way? One example is when each subject is measured at multiple times or under multiple conditions (group by subject ID). Another example is when you do identical replicates of the same experiment on different days (group by day). Yet another example is when your samples are randomized across several gels or plates because there are too many to fit on just one (group by gel or plate). Basically, any non-biological grouping of samples that would be different if the whole study was redone somewhere else. Choosing a grouping variable tells this app to use a mixed-effect linear model instead of the default fixed-effect one. It is possible to have grouped survival/time-to-event data, but at this time it is beyond the scope of this app. It is also possible to have multiple levels of grouping (e.g. repeated measures on each mouse, and the mice themselves are grouped into litters or batches). That too is currently beyond the scope of this app. If you have a complex grouping structure in your data, make sure to let you statistician know when they review these results. Also, if the reason your data are grouped is because they represent longitudinal measurements over time in the same subjects, AND it looks like the response peaks at a certain time and then goes down, that is also beyond the scope of this app and is an important issue to discuss with your statistician. Use the code-word 'time series with non-monotonic, non-linear response'.",
            xvarHelp="These are the 'ordinary' variables. All of them start out already selected and the app will try to weed out the ones that don't contribute to the model fit. Manually remove the ones that you know are redundant (i.e. because someone created them from other variables... actual raw data are not necessarily redundant just because they correlate highly with each other). A ratio or other function of two variables is only redundant if you include both of the variables, but not if you include just one. Other candidates for prior removal are things the app mistook for data, like dates or comments. But there is a fine line between that and grouping variables. Keep everything else, and the model will decide what to leave in and what to leave out. If you aren't sure whether or not to remove a variable, ask your statistician. Code-word 'variable selection'.",
            cvarHelp="If you have survival/time-to-event data, you must have a column of censoring indicators set to 0 if observation of the subject stopped for ANY reason other than the event of interest ocurring (including the study period elapsing) and 1 if it was a normal, non-censored event. The response variable should be either the time the even occurred or the time at which that subject was censored. Examples of censored events would be animals dying to fighting or malocclusion (unless you are studying fighting or malocclusion) or animals that spend the maximum amount of time on the rotarod without falling off. To be absolutely clear: if you do not keep track of censored events, you are distorting your results. The censoring column is how you tell this app to use a time-to-event model instead of a linear model.",
            yvarHelp="This is the quantity you are measuring, sometimes called the dependent variable. If the variable you were expecting is not showing up in this list it may mean at least one value was in a non-numeric format, or that there are too few distinct values relative to the sample size. If the former case, please proof-read your data and try again. In the latter case, it's beyond the scope of this app and you might want to tell your statistician the code-word 'discrete response variable'. Or, maybe the sample size is simply too small for meaningful analysis.",
            colBetaHelp="The beta column is estimate of the term's effect. Note that it can go in either direction, up or down.",
            colEffectHelp="The Effect column is the same as the Beta column except if you specified a survival model by choosing a censoring indicator. In that case the Effect is the fold-change in the probability of the event ocurring relative to the reference group and the Beta is the log of that. For the Cox proportional hazard model this app uses FOR SURVIVAL/TIME-TO-EVENT DATA, EFFECT>1 MEANS SHORTER TIMES UNTIL THE EVENT HAPPENS AND AN EFFECT<1 MEANS LONGER TIMES.",
            colErrorHelp="The Error column is the standard error of the Beta estimate.",
            colDFHelp="The DF column (if present) represents the RESIDUAL degrees of freedom. If you don't know what that means, don't worry about it, and if you do, you might like to know that if you chose a grouping variable for your model, these are estimated degrees of freedom and may be different for different terms.",
            colStatisticHelp="The Statistic column is the test statistic-- z-score for survival data and t-statistic for linear models. Yes, it's used to get the p-value and no, that doesn't mean you're doing a Student's T-test. For more information, ask your statistician about the code word 'wald test' or about 'what is the square of a t-statistic'.",
            colpHelp="The p-values. Not all p-values are relevant to your hypothesis. For example the one for the intercept is almost never relevant. The ones that matter the most are the ones for your variable of interest and for interaction terms containing that variable (BOTH matter, see above). Generally if a variable is significant but does not interact with your main variable and doesn't interact with anything that interacts with your main main variable, you can mention in passing that it was significant, but its relevance to your hypothesis is limited to the fact that it independently influences the response and by including it in the model, you have taken it into account.",
            colChangeHelp="The Change column is not a traditional statistic, just something added for your convenience-- 2 indicates an increase in Beta with p<0.05, 1 indicates increase in Beta with p>0.05, -1 indicates a decrease in Beta with p>0.05, and a -2 indicates a decrease in Beta with p<0.05.",
            colTermHelp="Welcome to the longest help pop-up so far. These are not obscure technical details. Everything here matters if you want to correctly analyze and interpret your data, and is written in as close to plain English as I could manage. Let's get started. Each row represents a hypothesis test for one of the terms in the model. The intercept is the estimated response for the reference group (the group that has the control value for each variable). If a term has a variable name immediately followed by its level, it means the app thinks the variable is categorical (e.g. male/female, wildtype/mutant, control/treated). Such a term represents the DIFFERENCE in response between that level and the reference level (represented by the intercept). If a term has just the variable name, it means the app thinks the variable is numeric. Such a term represents the PER-UNIT CHANGE in response (e.g. change in rotarod time per gram of body weight, change in expression per microgram of drug). Some terms will contain more than one variable separated by ':'s. These are interaction terms. If at least one variable is categoric, you can interpret the term to mean the 'difference between the differences' (e.g. how differently do males and females respond to the treatment?). If both variables are numeric, you can interpret the term as how one numeric variable adjusts the per-unit effect of the other (e.g. how much is the change in rotarod time per gram of body weight affected by each additional day of age?). LEAVING A SIGNIFICANT INTERACTION OUT OF YOUR MODEL WILL LEAD TO FALSE POSITIVES OR FALSE NEGATIVES AND MAY PRODUCE A PERFECTLY VALID-LOOKING RESULT THAT WILL FOOL YOU AND YOUR REVIEWERS. Even an non-significant interaction can still cause misinterpreted results if omitted. On the other hand, including every possible interaction in your model will also result in errors (again, of both types). The key is to strike a balance and this app's model selection algorithm attempts to do so. You can and should ask a human statistician for a second opinion. And then ask them to compare the AIC of their model against the AIC of this one (or do a likelihood ratio test if the models are nested, they should know what that means). There is another subtle problem to consider here. Let's say that the reference treatment is 'control', the reference genotype is 'wildtype', the reference sex (whatever that means) is 'male'... but what about the numeric variables? Well, by default their reference value is... ZERO! So if any of your variables are numeric, then this (and all other statistical software) is giving you estimates for each term while holding all the numeric variables not part of that term constant at zero. If the model assumptions are met, the estimates will still be correct, but wouldn't you rather know how the response of untreated and treated subjects differs when they are at the experiment-wide mean body weight rather than how much it would hypothetically differ if they all had a body weight of zero? The solution is to center your numeric variables so that the new zeros represent overall averages, or maybe the average values at the start of the experiment, or some other meaningful quantity within the support range of the data. I intend to add such a feature to the app in the future, but in the meantime, you might consider manually centering your numeric values.",
            modelSearchHelp="We start out with a simple additive model with all the terms you selected. Then we add and discard terms until the fit of the model stops improving. Below is a table comparing the models that were tried. The one with the smallest AIC value is generally the one you should use.");
